{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ones = u.read_ones(data_path / 'train.csv')\n",
    "# u.add_more_time(ones)\n",
    "# ones = ones.rename(columns={'sid': 'segment_id', 'day': 'weekday'})\n",
    "\n",
    "# vehinj = u.read_vehinj(Path('../data/SANRAL_v2'))\n",
    "\n",
    "# field_combs = [\n",
    "#     tuple([('segment_id')]), tuple(['hour']), tuple(['weekday']), tuple(['month']),\n",
    "#     ('segment_id', 'hour'), ('segment_id', 'weekday'), ('segment_id', 'month'), ('weekday', 'month'), ('hour', 'weekday'),\n",
    "#     ('segment_id', 'weekday', 'hour'), ('segment_id', 'weekday', 'month')\n",
    "# ]\n",
    "\n",
    "\n",
    "# train = u.select_by_time(train_full, '2017-01-01', '2018-10-01')\n",
    "# u.add_statistic(data=train, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2017-01-01',\n",
    "#                )\n",
    "\n",
    "# val = u.select_by_time(train_full, '2018-10-01', '2019-01-01')\n",
    "# u.add_statistic(data=val, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2018-10-01',\n",
    "#                )\n",
    "\n",
    "# u.add_statistic(data=test, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2019-01-01',\n",
    "#                )\n",
    "\n",
    "# x_cols = cols\n",
    "# x_cols.extend([c for c in train.columns if c.startswith('hist_')])\n",
    "\n",
    "# train = u.select_by_time(train_full, '2016-01-01', val_tstart, time_col='datetime')\n",
    "# val = u.select_by_time(train_full, val_tstart, '2019-01-01', time_col='datetime')\n",
    "\n",
    "# def prepare(df):\n",
    "#     df[cat_cols] = df[cat_cols].replace(np.nan, 'NAN').astype('object')\n",
    "#     df[cat_cols] = df[cat_cols].astype('str')\n",
    "    \n",
    "\n",
    "# prepare(train_full)\n",
    "# prepare(test)\n",
    "\n",
    "# val = train_full.loc[ids_val]\n",
    "# val.reset_index(inplace=True)\n",
    "\n",
    "# u.run_many_th_experiment(val, np.array(predictions), th_score=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import catboost\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "from pathlib import Path\n",
    "import src.data_utils as u\n",
    "import src.fai_utils as f\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "u.random_seed(42)\n",
    "\n",
    "data_path = Path('../data')\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_pickle(data_path / 'train_v2q_opt.pkl')\n",
    "test = pd.read_pickle(data_path / 'test_v2q_opt.pkl')\n",
    "\n",
    "x_cols = train_full.columns.values.tolist()\n",
    "\n",
    "cat_cols = [\n",
    "       'segment_id', 'weekday', 'month', 'hour', 'dayofyear',\n",
    "       'weekofyear', 'ROADNO', 'CLASS', 'SURFTYPE', \n",
    "       'PAVETYPE', 'CONDITION', 'vds_id','vms_count', 'vds_count','wind_dir', 'cloud_cover',\n",
    "       'weather_cond', 'cloud_1', 'cloud1_cover', 'cloud_height', 'cloud_2', 'precip_mm',\n",
    "       'cloud_3', 'precip_time', 'public_holiday', 'school_holiday'\n",
    "]\n",
    "\n",
    "cont_names = list(set(x_cols) - set(cat_cols))\n",
    "cont_names.remove('datetime x segment_id')\n",
    "cont_names.remove('datetime')\n",
    "cont_names.remove('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in cont_names:\n",
    "    test[f] = test[f].fillna(0)\n",
    "    train_full[f] = train_full[f].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tstart = '2018-10-01'\n",
    "ids_val = train_full[train_full.datetime >= pd.Timestamp(val_tstart)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]\n",
    "\n",
    "test_tab = TabularList.from_df(test, cat_names=cat_cols, cont_names=cont_names)\n",
    "\n",
    "data = (TabularList.from_df(train_full, procs=procs, cat_names=cat_cols, cont_names=cont_names)\n",
    "                   .split_none()\n",
    "                   .label_from_df(cols='y')\n",
    "                   .add_test(test_tab)\n",
    "                   .databunch(bs=200_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([1, 10]).float().to(device)\n",
    "\n",
    "learn = tabular_learner(data, path='../results/fai', layers=[128],\n",
    "                        metrics=u.F1(th_start=0, th_stop=1, steps=20),\n",
    "                        callback_fns=[ShowGraph,\n",
    "                                      partial(EarlyStoppingCallback,\n",
    "                                              monitor='f1', min_delta=0.001, patience=5)\n",
    "                                      ],\n",
    "                        loss_func=torch.nn.CrossEntropyLoss(weight=weights),\n",
    "                        opt_func=torch.optim.Adam\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with one fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_func = lambda learn: learn.fit(1, slice(5e-03),\n",
    "                                   callbacks=[\n",
    "                                       SaveModelCallback(learn, every='improvement',\n",
    "                                                         monitor='f1', name='best')\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.data.split_by_idx(ids_val)\n",
    "\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "plt.show()\n",
    "\n",
    "fit_func(learn)\n",
    "\n",
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, *_ = learn.get_preds(DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_arr, scores = f.fit_predict_cv(val_ids=ids_val, learn=learn, fit_func=fit_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = predictions_arr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.estimate(learn, validation_pool=None, y_true=train_full.y[ids_val],\n",
    "           th_start=0, th_stop=1, steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = cont_names + cat_cols\n",
    "\n",
    "train = train_full[train_full.datetime < pd.Timestamp(val_tstart)]\n",
    "val = train_full[train_full.datetime >= pd.Timestamp(val_tstart)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "    df[cat_cols] = df[cat_cols].replace(np.nan, 'NAN').astype('object')\n",
    "    df[cat_cols] = df[cat_cols].astype('str')\n",
    "\n",
    "    \n",
    "prepare(train)\n",
    "prepare(val)\n",
    "prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=train[x_cols], label=train['y'], cat_features=cat_cols)\n",
    "val_pool =  Pool(data=val[x_cols], label=val['y'], cat_features=cat_cols)\n",
    "test_pool = Pool(data=test[x_cols], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --bootstrap-type\n",
    "# --bagging-temperature\n",
    "# --random-strength\n",
    "# --depth\n",
    "# --grow-policy\n",
    "# --max-leaves\n",
    "# --one-hot-max-size\n",
    "# --rsm\n",
    "# --boosting-type\n",
    "# --boost-from-average\n",
    "# --model-shrink-rate\n",
    "\n",
    "params = {\n",
    "    'iterations': 350,\n",
    "    'learning_rate': 0.05,\n",
    "    'scale_pos_weight': 10,\n",
    "    'has_time': False,\n",
    "    'depth': 10,\n",
    "    'one_hot_max_size': 1000,\n",
    "    \n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'CPU',\n",
    "    'use_best_model': True,\n",
    "    'eval_metric': m.FlexibleF1(0, 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv(pool=train_pool,\n",
    "   params=params,\n",
    "   plot=True,\n",
    "   early_stopping_rounds=10,\n",
    "   fold_count=3,\n",
    "   stratified=True,\n",
    "   logging_level='Verbose'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = CatBoostClassifier(**params)\n",
    "\n",
    "cls.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    plot=True,\n",
    "    verbose=1,\n",
    "    early_stopping_rounds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls = CatBoostClassifier()\n",
    "# cls.load_model(str(model_path))\n",
    "\n",
    "cls.save('../results/model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = u.estimate(cls, val_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attemption of postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = val['y'].astype(bool)\n",
    "probas = cls.predict_proba(val_pool)[:, 1] \n",
    "pred = probas > th\n",
    "\n",
    "n_th = 0\n",
    "w_events = (val.cnt_event_with_veh > n_th) | (val.cnt_event_with_inj > n_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehinj = vehinj.drop_duplicates('EventID', keep='last')\n",
    "vehinj.time = vehinj.time.dt.floor('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probas_to_pred(data_fixed_t: pd.DataFrame, n_vehinj: int) -> np.ndarray:\n",
    "    probas = np.array(data_fixed_t['probas'])\n",
    "    \n",
    "    pred = probas > th\n",
    "    \n",
    "    if abs(n_vehinj - pred.sum()) > 15:\n",
    "        pred = np.zeros(len(data_fixed_t))\n",
    "        \n",
    "        ii_top = np.argsort(probas)[-round(3 * n_vehinj):]\n",
    "        pred[ii_top] = 1\n",
    "        \n",
    "    return pred.astype(bool)\n",
    "\n",
    "\n",
    "def postproc(data: pd.DataFrame, vehinj: pd.DataFrame) -> np.ndarray:\n",
    "    assert {'time', 'probas'} - set(data.columns) == set()\n",
    "\n",
    "    # get time -> n_events mapping from raw table\n",
    "    vehinj = vehinj.drop_duplicates('EventID', keep='last')\n",
    "    vehinj.time = vehinj.time.dt.floor('H')\n",
    "    time_to_nevents = Counter(vehinj.time)\n",
    "\n",
    "    pred = np.zeros(len(data))\n",
    "    for t in tqdm(set(data.time)):\n",
    "\n",
    "        wt = data.time == t\n",
    "        data_t = data[wt]\n",
    "\n",
    "        n = time_to_nevents[t]\n",
    "        if n == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pred[wt] = probas_to_pred(n_vehinj=n, data_fixed_t=data_t)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "val['probas'] = probas\n",
    "pred3 = postproc(data=val, vehinj=vehinj)\n",
    "\n",
    "print(sum(pred3))\n",
    "u.scores(val_pool.get_label(), pred3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_npred   = Counter(val.time[pred])\n",
    "time_to_ngt     = Counter(val.time[gt])\n",
    "time_to_nvehinj = Counter(vehinj.time)\n",
    "\n",
    "data_events             = pd.DataFrame(data={'time': val.time.unique()})\n",
    "data_events['n_pred']   = data_events.time.apply(lambda t: time_to_npred[t])\n",
    "data_events['n_gt']     = data_events.time.apply(lambda t: time_to_ngt[t])\n",
    "data_events['n_vehinj'] = data_events.time.apply(lambda t: time_to_nvehinj[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events[1500:1550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(val[val.y.astype(bool)].segment_id).most_common(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('veh/inj event')\n",
    "u.plot_events(val.time[w_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sid = val.segment_id == 'AJRKP0C'\n",
    "\n",
    "print('predict')\n",
    "u.plot_events(val.time[w_sid & pred])\n",
    "print('groind truth')\n",
    "u.plot_events(val.time[w_sid & gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "sid_to_f1 = defaultdict(lambda : None)\n",
    "for sid in tqdm(set(val.segment_id)):\n",
    "    w_sid = val.segment_id == sid\n",
    "    f = f1_score(y_true=val_pool.get_label().astype(bool)[w_sid], y_pred=pred[w_sid])\n",
    "    sid_to_f1[sid] = f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_pred = Counter(val.segment_id[pred])\n",
    "\n",
    "pred_info = [(sid, cnt_pred[sid], sid_to_f1[sid]) for sid in set(val.segment_id)]\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(sorted(pred_info, key=lambda tri: tri[2], reverse=True)[:30])\n",
    "\n",
    "sids, cnts, f1s = list(zip(*pred_info))\n",
    "plt.scatter(cnts, f1s)\n",
    "plt.xlabel('n pred')\n",
    "plt.ylabel('f1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top-pred and top-gt \n",
    "\n",
    "n_top = 25\n",
    "top_true = set([k for (k, _) in Counter(val.segment_id[val.y.astype(bool)]).most_common(n_top)])\n",
    "top_pred = set([k for (k, _) in Counter(val.segment_id[pred]).most_common(n_top)])\n",
    "\n",
    "iou_top = len(top_true.intersection(top_pred)) / len(top_true.union(top_pred))\n",
    "print(f'iou for top sids: {iou_top}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
