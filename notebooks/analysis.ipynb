{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!! pip install geopandas \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import src.data_utils as u\n",
    "import src.model_utils as m\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "\n",
    "# avg events hour rate: 0.37% \n",
    "DATA = Path('../data/')\n",
    "RESULT = Path('../results/')\n",
    "\n",
    "train_path = DATA / 'train.csv'\n",
    "shape_path = DATA / 'road_segments' / 'road_segments.shp'\n",
    "velocity_path = DATA / 'data_velocity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injurence and velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, parse_dates = ['Occurrence Local Date Time'])\n",
    "\n",
    "\n",
    "inj = pd.read_csv(DATA / 'SANRAL_v2' / 'Injuries2016_2019.csv', parse_dates=['Created Local Date Time'])\n",
    "inj = inj.rename(columns={'Created Local Date Time': 'time'})\n",
    "inj = u.select_by_time(inj, '2016-01-01', '2019-01-01')\n",
    "\n",
    "\n",
    "veh = pd.read_csv(DATA / 'SANRAL_v2' / 'Vehicles2016_2019.csv')\n",
    "veh = veh.fillna(0)\n",
    "veh['EventID'] = veh.EventID.astype(int)\n",
    "veh = veh.head(n=63469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9218 12565 13909\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "len(set(train.EventId) - (set(veh.EventID) | set(inj['Event Id']))),\n",
    "len((set(veh.EventID) | set(inj['Event Id'])) - set(train.EventId)),\n",
    "len(set(inj['Event Id']).intersection(set(veh.EventID)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ones = u.read_ones(train_path)\n",
    "\n",
    "data_a = u.select_by_time(data_ones, '2016-01-01', '2016-12-31')\n",
    "data_b = u.select_by_time(data_ones, '2018-01-01', '2018-12-31')\n",
    "data_c = u.select_by_time(data_ones, '2017-01-01', '2017-12-31')\n",
    "\n",
    "union_sids = set(data_a.sid).intersection(set(data_b.sid)).intersection(set(data_c.sid))\n",
    "\n",
    "data_a = data_a[data_a.sid.isin(union_sids)]\n",
    "data_b = data_b[data_b.sid.isin(union_sids)]\n",
    "data_c = data_c[data_c.sid.isin(union_sids)]\n",
    "\n",
    "count_a = data_a.groupby('sid').count().sort_values(by='sid')\n",
    "count_b = data_b.groupby('sid').count().sort_values(by='sid')\n",
    "count_c = data_c.groupby('sid').count().sort_values(by='sid')\n",
    "\n",
    "\n",
    "print(kendalltau(count_a.target, count_b.target))\n",
    "print(kendalltau(count_a.target, count_c.target))\n",
    "print(kendalltau(count_b.target, count_c.target))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
