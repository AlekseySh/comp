{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import catboost\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from pathlib import Path\n",
    "import src.utils as u\n",
    "import src.cb_utils as m\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "u.random_seed(42)\n",
    "\n",
    "data_path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, test, all_cols, cont_cols, cat_cols = u.read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = train_full[all_cols].corr()\n",
    "\n",
    "# high_corr = []\n",
    "# fields = corr.columns\n",
    "\n",
    "# for f1 in fields:\n",
    "#     for f2 in fields:\n",
    "#         if (f1 != f2) and (corr[f1][f2] > 0.8) and ({f1, f2} not in high_corr):\n",
    "#             print(f1, f2, corr[f1][f2])\n",
    "#             high_corr.append({f1, f2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_to_drop = ['longitude', 'latitude', 'LANES', 'lane_width', 'P0',\n",
    "                     'mean_avg_speed', 'traffic_total', 'std_traffic', 'traffic1']\n",
    "\n",
    "all_cols = list(set(all_cols) - set(high_corr_to_drop))\n",
    "cont_cols = list(set(cont_cols) - set(high_corr_to_drop))\n",
    "cat_cols = list(set(cat_cols) - set(high_corr_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011583073220570936"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_full['traffic_total'].isnull()) / len(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([u.select_by_time(train_full, '2016-01-01', '2018-01-01', 'datetime'),\n",
    "                   u.select_by_time(train_full, '2018-04-01', '2019-01-01', 'datetime')])\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "val = u.select_by_time(train_full, '2018-01-01', '2018-04-01', 'datetime')\n",
    "\n",
    "\n",
    "def get_folds(df):\n",
    "    months = [('2018-04-01', '2018-06-30'),\n",
    "              ('2018-07-01', '2018-09-30'),\n",
    "              ('2018-10-01', '2019-01-01')]\n",
    "    \n",
    "    folds = []\n",
    "    for (ta, tb) in months:\n",
    "        tstart = pd.Timestamp(ta)\n",
    "        tend = pd.Timestamp(tb)\n",
    "\n",
    "        tt = df.datetime\n",
    "        ids_val = ((tstart <=  tt) & (tt < tend)).to_numpy().nonzero()[0]\n",
    "        ids_val = np.array(ids_val)\n",
    "        folds.append(ids_val)\n",
    "    \n",
    "    return folds\n",
    "        \n",
    "    \n",
    "folds = get_folds(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pool = Pool(data=val[all_cols], label=val['y'], cat_features=cat_cols)\n",
    "test_pool = Pool(data=test[all_cols], label=test['y'], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probas, ths, val_scores = m.fit_predict_cv(train=train,\n",
    "                                           test=val,\n",
    "                                           val_ids=folds, \n",
    "                                           cat_cols=cat_cols,\n",
    "                                           all_cols=all_cols,\n",
    "                                           draw_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_fold, (th, proba) in enumerate(zip(ths, probas)):\n",
    "    print(u.f1_flexible(proba, th_start=0, th_stop=1, steps=20, gts=val.y)[0])\n",
    "    print(f1_score(y_pred=proba > th, y_true=val.y))\n",
    "    print(sum(proba > th))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vote = m.vote_predict(probas, ths)\n",
    "f1_score(y_pred=y_pred_vote, y_true=val.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = m.load_models('/home/AlekseySh/code/comp/results/cb/2020-02-02 02:03:13.874913/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_multi_models(models, ths, val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.estimate(models[1], val_pool, val_pool.get_label())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 FOLD VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_combs = [\n",
    "    tuple([('segment_id')]), tuple(['hour']), tuple(['weekday']), tuple(['month']),\n",
    "    ('segment_id', 'hour'), ('segment_id', 'weekday'), ('segment_id', 'month'), ('weekday', 'month'), ('hour', 'weekday'),\n",
    "    ('segment_id', 'weekday', 'hour'), ('segment_id', 'weekday', 'month')\n",
    "]\n",
    "\n",
    "ones = u.read_ones('../data/train.csv')\n",
    "ones['segment_id'] = ones['sid']\n",
    "u.add_more_time(ones)\n",
    "\n",
    "train = u.select_by_time(train_full, '2018-01-01', '2018-10-01', 'datetime')\n",
    "u.add_statistic(data=train, stat_data=ones,\n",
    "                field_combs=field_combs, prefix='hist_',\n",
    "                tstart='2016-01-01', tend='2018-01-01',\n",
    "               )\n",
    "\n",
    "val = u.select_by_time(train_full, '2018-10-01', '2019-01-01', 'datetime')\n",
    "u.add_statistic(data=val, stat_data=ones,\n",
    "                field_combs=field_combs, prefix='hist_',\n",
    "                tstart='2016-01-01', tend='2018-10-01',\n",
    "               )\n",
    "\n",
    "u.add_statistic(data=test, stat_data=ones,\n",
    "                field_combs=field_combs, prefix='hist_',\n",
    "                tstart='2016-01-01', tend='2019-01-01',\n",
    "               )\n",
    "\n",
    "\n",
    "hist_cols = list(filter(lambda x: x.startswith('hist_'), train.columns.values))\n",
    "\n",
    "all_cols += hist_cols\n",
    "cont_cols += hist_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=train[all_cols], label=train['y'], cat_features=cat_cols)\n",
    "val_pool =  Pool(data=val[all_cols], label=val['y'], cat_features=cat_cols)\n",
    "test_pool = Pool(data=test[all_cols], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --bootstrap-type\n",
    "# --bagging-temperature\n",
    "# --random-strength\n",
    "# --depth\n",
    "# --grow-policy\n",
    "# --max-leaves\n",
    "# --rsm\n",
    "# --boost-from-average\n",
    "# --model-shrink-rate\n",
    "\n",
    "params = {\n",
    "    'iterations': 10000,\n",
    "    'learning_rate': 0.05,\n",
    "    'scale_pos_weight': 10,\n",
    "    'has_time': False,\n",
    "    'one_hot_max_size': 100,\n",
    "    'depth': 4,\n",
    "    \n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'GPU',\n",
    "    'use_best_model': True,\n",
    "    'eval_metric': 'F1'#m.FlexibleF1(0, 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = CatBoostClassifier(**params)\n",
    "\n",
    "cls.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    plot=True,\n",
    "    verbose=1,\n",
    "    early_stopping_rounds=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = u.estimate(cls, val_pool, y_true=val_pool.get_label(), steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test = cls.predict_proba(test_pool)[:, 1]\n",
    "proba_val = cls.predict_proba(val_pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = proba_val > th\n",
    "\n",
    "print(f1_score(y_true=val.y, y_pred=pred_val))\n",
    "\n",
    "# heuristic\n",
    "pred_val[val.hour <= 4] = 0\n",
    "pred_val[val.hour >= 22] = 0\n",
    "\n",
    "print(f1_score(y_true=val.y, y_pred=pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls = CatBoostClassifier()\n",
    "# cls.load_model('../results/model_cb.pt')\n",
    "\n",
    "# cls.save_model('../results/cb/stack/model_1159.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = proba_test > 1.18 * th\n",
    "\n",
    "n_pred = sum(pred)\n",
    "print(n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(\n",
    "    data={'datetime x segment_id': test['datetime x segment_id'].values,\n",
    "          'prediction': pred.astype(int)}\n",
    ")\n",
    "submit.to_csv(f'../results/submit_cb_{n_pred}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
