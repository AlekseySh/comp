{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import catboost\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from pathlib import Path\n",
    "import src.utils as u\n",
    "import src.cb_utils as m\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "u.random_seed(42)\n",
    "\n",
    "data_path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_full, test, all_cols, cont_cols, cat_cols = u.read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # corr = train_full[all_cols].corr()\n",
    "\n",
    "# high_corr = []\n",
    "# fields = list(set(corr.columns) - set(high_corr_to_drop))\n",
    "\n",
    "# for f1 in fields:\n",
    "#     for f2 in fields:\n",
    "#         if (f1 != f2) and (corr[f1][f2] > 0.90) and ({f1, f2} not in high_corr):\n",
    "#             print(f1, f2, corr[f1][f2])\n",
    "#             high_corr.append({f1, f2})\n",
    "            \n",
    "# print(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_to_drop = ['longitude', 'latitude', 'LANES', 'lane_width', 'P0', 'dist_to_center', 'traffic1',\n",
    "                    'avg_speed_neigh', 'traffic_total_neigh',\n",
    "                    'average_ttime_neigh', 'acc_cnt_last_quarter_sid_neigh',\n",
    "                    'mean_traffic', 'acc_cnt_last_halfyear_sid_neigh',\n",
    "                    # with low feature importance\n",
    "                    \n",
    "                     'cloud_cover',\n",
    "                     'cloud1_cover',\n",
    "                     'acc_cnt_last_halfyear_sid_wd_h_neigh',\n",
    "                     'delta_rel_diff_traffic_last_hour',\n",
    "                     'rel_diff_traffic',\n",
    "                     'acc_cnt_last_halfyear_vds',\n",
    "                     'delta_traffic_total_next_hour',\n",
    "                     'temp',\n",
    "                     'acc_cnt_last_halfyear_vds_wd',\n",
    "                     'orientation',\n",
    "                     'cloud_3',\n",
    "                     'wind_speed',\n",
    "                     'wind_dir_angle',\n",
    "                     'max_gust',\n",
    "                     'weather_cond',\n",
    "                     'blinding',\n",
    "                     'acc_cnt_last_quarter_vds_wd',\n",
    "                     'cloud_height',\n",
    "                     'delta_traffic_total_last_hour',\n",
    "                     'wind_dir',\n",
    "                     'delta_rel_diff_traffic_next_hour',\n",
    "                     'acc_cnt_last_quarter_sid_wd_h_neigh',\n",
    "                     'precip_time',\n",
    "                     'humidity',\n",
    "                     'angle_wind_road',\n",
    "                     'cloud_1',\n",
    "                     'mean_avg_speed',\n",
    "                     'acc_cnt_last_halfyear_vds_wd_h',\n",
    "                     'cloud_2',\n",
    "                     'sinuosity',\n",
    "                     'wind_dir_defined',\n",
    "                     'vds_count',\n",
    "                     'snow',\n",
    "                     'CLASS',\n",
    "                     'mist',\n",
    "                     'vms_count',\n",
    "                     'PAVETYPE',\n",
    "                     'delta_average_ttime_last_day',\n",
    "                     'average_ttime_na',\n",
    "                     'precip_mm',\n",
    "                     'SURFTYPE',\n",
    "                     'smoke',\n",
    "                     'fog',\n",
    "                     'drizzle',\n",
    "                     'cloud_cover_fog',\n",
    "                     'delta_average_ttime_next_day',\n",
    "                     'WIDTH',\n",
    "                     'visibility',\n",
    "                     'rain',\n",
    "                     'main_route']\n",
    "\n",
    "all_cols = list(set(all_cols) - set(high_corr_to_drop))\n",
    "cont_cols = list(set(cont_cols) - set(high_corr_to_drop))\n",
    "cat_cols = list(set(cat_cols) - set(high_corr_to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([u.select_by_time(train_full, '2016-01-01', '2018-01-01', 'datetime'),\n",
    "#                    u.select_by_time(train_full, '2018-04-01', '2019-01-01', 'datetime')])\n",
    "# train.reset_index(inplace=True)\n",
    "\n",
    "# val = u.select_by_time(train_full, '2018-01-01', '2018-04-01', 'datetime')\n",
    "\n",
    "\n",
    "# def get_folds(df):\n",
    "#     months = [('2018-04-01', '2018-06-30'),\n",
    "#               ('2018-07-01', '2018-09-30'),\n",
    "#               ('2018-10-01', '2019-01-01')]\n",
    "    \n",
    "#     folds = []\n",
    "#     for (ta, tb) in months:\n",
    "#         tstart = pd.Timestamp(ta)\n",
    "#         tend = pd.Timestamp(tb)\n",
    "\n",
    "#         tt = df.datetime\n",
    "#         ids_val = ((tstart <=  tt) & (tt < tend)).to_numpy().nonzero()[0]\n",
    "#         ids_val = np.array(ids_val)\n",
    "#         folds.append(ids_val)\n",
    "    \n",
    "#     return folds\n",
    "        \n",
    "    \n",
    "# folds = get_folds(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pool = Pool(data=val[all_cols], label=val['y'], cat_features=cat_cols)\n",
    "# test_pool = Pool(data=test[all_cols], label=test['y'], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# probas, ths, val_scores = m.fit_predict_cv(train=train,\n",
    "#                                            test=val,\n",
    "#                                            val_ids=folds, \n",
    "#                                            cat_cols=cat_cols,\n",
    "#                                            all_cols=all_cols,\n",
    "#                                            draw_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_fold, (th, proba) in enumerate(zip(ths, probas)):\n",
    "#     print(u.f1_flexible(proba, th_start=0, th_stop=1, steps=20, gts=val.y)[0])\n",
    "#     print(f1_score(y_pred=proba > th, y_true=val.y))\n",
    "#     print(sum(proba > th))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_vote = m.vote_predict(probas, ths)\n",
    "# f1_score(y_pred=y_pred_vote, y_true=val.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = m.load_models('/home/AlekseySh/code/comp/results/cb/2020-02-02 02:03:13.874913/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = predict_multi_models(models, ths, val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u.estimate(models[1], val_pool, val_pool.get_label())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = u.select_by_time(train_full, '2016-07-01', '2019-01-01', 'datetime')\n",
    "pool = Pool(data=train_total[all_cols], label=train_total['y'], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(data=test[all_cols], label=test['y'], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'scale_pos_weight': 5,\n",
    "    'has_time': True,\n",
    "    'one_hot_max_size': 1000,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 6,\n",
    "    'grow_policy': 'SymmetricTree', # SymmetricTree, Lossguide, Depthwise\n",
    "    \n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'CPU',\n",
    "    # 'eval_metric': 'F1', # m.FlexibleF1(0, 1, 20)\n",
    "    'custom_loss': 'F1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_res = cv(\n",
    "   pool=pool, \n",
    "   params=params, \n",
    "   iterations=600,\n",
    "   fold_count=5, \n",
    "   seed=42, \n",
    "   shuffle=True, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   verbose=1,\n",
    "   plot=True,\n",
    "   early_stopping_rounds=600,\n",
    "   type='Classical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 150,\n",
    "    'learning_rate': 0.1,\n",
    "    'scale_pos_weight': 5,\n",
    "    'has_time': True,\n",
    "    'one_hot_max_size': 1000,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 6,\n",
    "    'grow_policy': 'SymmetricTree', # SymmetricTree, Lossguide, Depthwise\n",
    "    \n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'CPU',\n",
    "    'custom_loss': 'F1',\n",
    "    'train_dir': 'train_on_full'\n",
    "}\n",
    "\n",
    "cls = CatBoostClassifier(**params)\n",
    "\n",
    "cls.fit(\n",
    "    pool,\n",
    "    verbose=10,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test = cls.predict_proba(test_pool)[:, 1]\n",
    "proba_train = cls.predict_proba(pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.estimate(cls, pool, pool.get_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.save_model('../results/cb_150_it_on_full.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_unk = train_total.traffic_unknown == '1'\n",
    "u.f1_flexible(proba_train[w_unk], train_total.y[w_unk], 0, 1, 20)\n",
    "u.f1_flexible(proba_train[~w_unk], train_total.y[~w_unk], 0, 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 FOLD VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_combs = [\n",
    "#     tuple([('segment_id')]), tuple(['hour']), tuple(['weekday']), tuple(['month']),\n",
    "#     ('segment_id', 'hour'), ('segment_id', 'weekday'), ('segment_id', 'month'), ('weekday', 'month'), ('hour', 'weekday'),\n",
    "#     ('segment_id', 'weekday', 'hour'), ('segment_id', 'weekday', 'month')\n",
    "# ]\n",
    "\n",
    "# ones = u.read_ones('../data/train.csv')\n",
    "# ones['segment_id'] = ones['sid']\n",
    "# u.add_more_time(ones)\n",
    "\n",
    "# train = u.select_by_time(train_full, '2018-01-01', '2018-10-01', 'datetime')\n",
    "# u.add_statistic(data=train, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2018-01-01',\n",
    "#                )\n",
    "\n",
    "# val = u.select_by_time(train_full, '2018-10-01', '2019-01-01', 'datetime')\n",
    "# u.add_statistic(data=val, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2018-10-01',\n",
    "#                )\n",
    "\n",
    "# u.add_statistic(data=test, stat_data=ones,\n",
    "#                 field_combs=field_combs, prefix='hist_',\n",
    "#                 tstart='2016-01-01', tend='2019-01-01',\n",
    "#                )\n",
    "\n",
    "\n",
    "# hist_cols = list(filter(lambda x: x.startswith('hist_'), train.columns.values))\n",
    "\n",
    "# all_cols += hist_cols\n",
    "# cont_cols += hist_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([u.select_by_time(train_full, '2017-07-01', '2018-01-01', 'datetime'),\n",
    "                   u.select_by_time(train_full, '2018-04-01', '2019-01-01', 'datetime')])\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "val = u.select_by_time(train_full, '2018-01-01', '2018-04-01', 'datetime')\n",
    "\n",
    "\n",
    "# train = u.select_by_time(train_full_high, '2016-10-01', '2018-10-01', 'datetime')\n",
    "# val = u.select_by_time(train_full_high, '2018-10-01', '2019-01-01', 'datetime')\n",
    "\n",
    "train_pool = Pool(data=train[all_cols], label=train['y'], cat_features=cat_cols)\n",
    "val_pool =  Pool(data=val[all_cols], label=val['y'], cat_features=cat_cols)\n",
    "test_pool = Pool(data=test[all_cols], cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --bootstrap-type\n",
    "# --bagging-temperature\n",
    "# --random-strength\n",
    "# --depth\n",
    "# --grow-policy\n",
    "# --max-leaves\n",
    "# --rsm\n",
    "# --boost-from-average\n",
    "# --model-shrink-rate\n",
    "\n",
    "params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'scale_pos_weight': 5,\n",
    "    'has_time': True,\n",
    "    'one_hot_max_size': 1000,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 6,\n",
    "    'grow_policy': 'SymmetricTree', # SymmetricTree, Lossguide, Depthwise\n",
    "    \n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'CPU',\n",
    "    'use_best_model': True,\n",
    "    'eval_metric': m.FlexibleF1(0, 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls = CatBoostClassifier(**params)\n",
    "\n",
    "cls.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    plot=True,\n",
    "    verbose=1,\n",
    "    early_stopping_rounds=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cls_grid = CatBoostClassifier(**{\n",
    "#     'loss_function': 'Logloss',\n",
    "#     'task_type': 'GPU',\n",
    "#     'eval_metric': 'F1'\n",
    "# })\n",
    "\n",
    "# param_grid = {'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "#               'depth': [2, 3, 4],\n",
    "#               'one_hot_max_size': [100, 255],\n",
    "#               'iterations': [1000],\n",
    "#               'class_weights': [[1, 3], [1, 5], [1, 10], [1, 20]],\n",
    "#               'early_stopping_rounds': [150],\n",
    "#               'l2_leaf_reg': [6, 12, 20],\n",
    "#               'grow_policy': ['SymmetricTree', 'Lossguide', 'Depthwise']\n",
    "#              }\n",
    "\n",
    "# grid_search_result = cls_grid.randomized_search(\n",
    "#             param_grid,\n",
    "#             X=train_pool,\n",
    "#             cv=2,\n",
    "#             partition_random_seed=42,\n",
    "#             stratified=True,\n",
    "#             train_size=0.8,\n",
    "#             verbose=True,\n",
    "#             plot=True,\n",
    "#             n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = u.estimate(cls, val_pool, y_true=val_pool.get_label(), th_start=0, th_stop=1, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_val = cls.predict_proba(val_pool)[:, 1]\n",
    "proba_test = cls.predict_proba(test_pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = proba_val > th\n",
    "print(sum(pred_val))\n",
    "\n",
    "print(f1_score(y_true=val.y, y_pred=pred_val))\n",
    "\n",
    "# heuristic\n",
    "pred_val[val.hour.astype(int) <= 3] = 0\n",
    "pred_val[val.hour.astype(int) >= 22] = 0\n",
    "\n",
    "print(f1_score(y_true=val.y, y_pred=pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls = CatBoostClassifier()\n",
    "# cls.load_model('../results/model_cb.pt')\n",
    "\n",
    "cls.save_model('../results/cb/model_1206.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# ii = np.argsort(-1 * cls.feature_importances_)[-50:]\n",
    "# pprint(list(zip(np.array(cls.feature_importances_)[ii], np.array(cls.feature_names_)[ii])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = proba_test > 0.285\n",
    "\n",
    "n_pred = sum(pred)\n",
    "print(n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(\n",
    "    data={'datetime x segment_id': test['datetime x segment_id'].values,\n",
    "          'prediction': pred.astype(int)}\n",
    ")\n",
    "submit.to_csv(f'../results/submit_cb_{n_pred}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
