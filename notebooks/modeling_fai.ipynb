{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "from torch.nn import CrossEntropyLoss as CEloss\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import src.utils as u\n",
    "import src.fai_utils as fu\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "u.random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "\n",
    "train_full, test, all_cols, cont_cols, cat_cols = u.read_data(data_path)\n",
    "\n",
    "for f in cont_cols:\n",
    "    test[f] = test[f].fillna(0)\n",
    "    train_full[f] = train_full[f].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = (train_full.datetime >= pd.Timestamp('2018-10-01')).values\n",
    "\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "\n",
    "data = (TabularList.from_df(\n",
    "            train_full, procs=procs, cat_names=cat_cols, cont_names=cont_cols)\n",
    "                 .split_by_idx(val_ids)\n",
    "                 .label_from_df(cols='y')\n",
    "                 .add_test(test_tab)\n",
    "                 .databunch(bs=100_000)\n",
    "       )\n",
    "\n",
    "test_tab = TabularList.from_df(df=test, cat_names=cat_cols, cont_names=cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[1024, 512, 256, 128],\n",
    "\n",
    "                                metrics=fu.F1(th_start=0, th_stop=1, steps=20),\n",
    "                                callback_fns=[ShowGraph,\n",
    "                                              partial(EarlyStoppingCallback,\n",
    "                                                      monitor='f1',\n",
    "                                                      min_delta=0.001,\n",
    "                                                      patience=5)\n",
    "                                              ],\n",
    "                                loss_func=CEloss(\n",
    "                                    weight=tensor([1, 10]).float().cuda()\n",
    "                                ),\n",
    "                                opt_func=torch.optim.Adam\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=slice(5e-3),\n",
    "                    callbacks=[\n",
    "                        SaveModelCallback(learn, every='improvement',\n",
    "                                          monitor='f1', name='best_model')]\n",
    "                   )\n",
    "                        \n",
    "learn.recorder.plot_losses()                        \n",
    "learn.recorder.plot_lr()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_val, *_ = learn.get_preds(DatasetType.Valid)\n",
    "probas_test, *_ = learn.get_preds(DatasetType.Test)\n",
    "\n",
    "probas_val = probas_val[:, 1]\n",
    "probas_test = probas_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = u.estimate(learn, val, y_true=val.y)  # th: 0.3838, f1 score: 0.1213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.array(probas_test) > th * .95  # we choose th to predict 8118 events\n",
    "\n",
    "n_pred = sum(pred_test)\n",
    "print(f'Predicted events: {n_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(\n",
    "    data={'datetime x segment_id': test['datetime x segment_id'].values,\n",
    "          'prediction': pred_test.astype(int)}\n",
    ")\n",
    "submit.to_csv(f'../results/submit_fai_{n_pred}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
